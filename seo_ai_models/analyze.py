#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è SEO –∞–Ω–∞–ª–∏–∑–∞ —Å–∞–π—Ç–∞ legalaipro.ru
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ GitHub Actions –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.
"""

import argparse
import json
import sys
import os
from datetime import datetime
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å –ø–æ–∏—Å–∫–∞ –º–æ–¥—É–ª–µ–π
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

try:
    from seo_ai_models.parsers.spa_parser import SPAParser
    from seo_ai_models.models.seo_advisor.analyzers.enhanced_content_analyzer import EnhancedContentAnalyzer
except ImportError as e:
    print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥—É–ª–∏ –∞–Ω–∞–ª–∏–∑–∞: {e}")
    print("–ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Ä–µ–∂–∏–º –∞–Ω–∞–ª–∏–∑–∞")
    SPAParser = None
    EnhancedContentAnalyzer = None


def analyze_url(url):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç URL —Å –ø–æ–º–æ—â—å—é —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞.
    
    Args:
        url: URL –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        
    Returns:
        dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
    """
    print(f"\nüîç –ù–∞—á–∏–Ω–∞–µ–º –∞–Ω–∞–ª–∏–∑ —Å–∞–π—Ç–∞: {url}")
    
    try:
        if SPAParser and EnhancedContentAnalyzer:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
            parser = SPAParser()
            analyzer = EnhancedContentAnalyzer()
            
            print("–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã...")
            content = parser.parse(url)
            
            print("–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞...")
            analysis = analyzer.analyze(content)
            
            return {
                "url": url,
                "timestamp": datetime.now().isoformat(),
                "status": "success",
                "content": content,
                "analysis": analysis
            }
        else:
            # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Ä–µ–∂–∏–º
            return create_simple_analysis(url)
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {str(e)}")
        import traceback
        traceback.print_exc()
        return {
            "url": url,
            "timestamp": datetime.now().isoformat(),
            "status": "error",
            "error": str(e)
        }


def create_simple_analysis(url):
    """
    –°–æ–∑–¥–∞–µ—Ç —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞ –ø–æ–ª–Ω—ã–µ –º–æ–¥—É–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.
    """
    print("‚ÑπÔ∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Ä–µ–∂–∏–º –∞–Ω–∞–ª–∏–∑–∞")
    
    return {
        "url": url,
        "timestamp": datetime.now().isoformat(),
        "status": "partial",
        "message": "–í—ã–ø–æ–ª–Ω–µ–Ω —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑",
        "basic_checks": {
            "url_accessible": True,
            "protocol": "https" if url.startswith("https://") else "http",
            "domain": url.split("//")[-1].split("/")[0]
        },
        "recommendations": [
            "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å–∞–π—Ç –¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ HTTPS",
            "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–∫–æ—Ä–æ—Å—Ç—å –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü",
            "–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–π—Ç–µ –º–µ—Ç–∞-—Ç–µ–≥–∏ –∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏",
            "–î–æ–±–∞–≤—å—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (Schema.org)",
            "–£–ª—É—á—à–∏—Ç–µ –≤–Ω—É—Ç—Ä–µ–Ω–Ω—é—é –ø–µ—Ä–µ–ª–∏–Ω–∫–æ–≤–∫—É"
        ]
    }


def generate_recommendations(analysis):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
    """
    recommendations = []
    
    recommendations.append("# üéØ SEO –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è legalaipro.ru\n")
    recommendations.append(f"**–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞:** {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}\n")
    recommendations.append(f"**URL:** {analysis.get('url', 'N/A')}\n")
    recommendations.append(f"**–°—Ç–∞—Ç—É—Å:** {analysis.get('status', 'N/A')}\n\n")
    
    recommendations.append("## üìä –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n\n")
    
    if analysis.get('status') == 'success' and 'analysis' in analysis:
        # –ï—Å–ª–∏ –µ—Å—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        analysis_data = analysis.get('analysis', {})
        
        if 'seo_score' in analysis_data:
            score = analysis_data['seo_score']
            recommendations.append(f"### SEO –û—Ü–µ–Ω–∫–∞: {score}/100\n\n")
        
        if 'issues' in analysis_data:
            recommendations.append("### üî¥ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã\n\n")
            for issue in analysis_data['issues']:
                recommendations.append(f"- {issue}\n")
            recommendations.append("\n")
    else:
        # –ë–∞–∑–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        basic_recs = analysis.get('recommendations', [])
        if basic_recs:
            recommendations.append("### –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n\n")
            for rec in basic_recs:
                recommendations.append(f"- {rec}\n")
            recommendations.append("\n")
    
    # –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö —Å–∞–π—Ç–æ–≤
    recommendations.append("## üí° –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–≥–æ —Å–∞–π—Ç–∞\n\n")
    recommendations.append("### –ö–æ–Ω—Ç–µ–Ω—Ç\n")
    recommendations.append("- –î–æ–±–∞–≤—å—Ç–µ –ø–æ–¥—Ä–æ–±–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ –ø–æ –∞–∫—Ç—É–∞–ª—å–Ω—ã–º –ø—Ä–∞–≤–æ–≤—ã–º –≤–æ–ø—Ä–æ—Å–∞–º\n")
    recommendations.append("- –°–æ–∑–¥–∞–π—Ç–µ FAQ —Ä–∞–∑–¥–µ–ª —Å —á–∞—Å—Ç–æ –∑–∞–¥–∞–≤–∞–µ–º—ã–º–∏ –≤–æ–ø—Ä–æ—Å–∞–º–∏\n")
    recommendations.append("- –ü—É–±–ª–∏–∫—É–π—Ç–µ –∫–µ–π—Å—ã –∏ –ø—Ä–∏–º–µ—Ä—ã —É—Å–ø–µ—à–Ω—ã—Ö –¥–µ–ª\n\n")
    
    recommendations.append("### –¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ SEO\n")
    recommendations.append("- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –º–µ—Ç–∞-—Ç–µ–≥–∏ (title, description) –¥–ª—è –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü\n")
    recommendations.append("- –î–æ–±–∞–≤—å—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ Schema.org (Organization, LegalService)\n")
    recommendations.append("- –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–π—Ç–µ —Å–∫–æ—Ä–æ—Å—Ç—å –∑–∞–≥—Ä—É–∑–∫–∏ (—Å–∂–∞—Ç–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –º–∏–Ω–∏—Ñ–∏–∫–∞—Ü–∏—è)\n")
    recommendations.append("- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ XML sitemap –∏ robots.txt\n\n")
    
    recommendations.append("### –õ–æ–∫–∞–ª—å–Ω–æ–µ SEO\n")
    recommendations.append("- –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Ç–µ—Å—å –≤ –Ø–Ω–¥–µ–∫—Å.–°–ø—Ä–∞–≤–æ—á–Ω–∏–∫–µ –∏ Google My Business\n")
    recommendations.append("- –£–∫–∞–∂–∏—Ç–µ –∞–¥—Ä–µ—Å –æ—Ñ–∏—Å–∞ –∏ –∫–æ–Ω—Ç–∞–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ö\n")
    recommendations.append("- –î–æ–±–∞–≤—å—Ç–µ –∫–∞—Ä—Ç—É —Å –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ–º –æ—Ñ–∏—Å–∞\n\n")
    
    recommendations.append("### –ö–æ–Ω–≤–µ—Ä—Å–∏—è\n")
    recommendations.append("- –†–∞–∑–º–µ—Å—Ç–∏—Ç–µ —á–µ—Ç–∫–∏–µ –ø—Ä–∏–∑—ã–≤—ã –∫ –¥–µ–π—Å—Ç–≤–∏—é (CTA)\n")
    recommendations.append("- –î–æ–±–∞–≤—å—Ç–µ –æ–Ω–ª–∞–π–Ω-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –∏–ª–∏ —á–∞—Ç-–±–æ—Ç\n")
    recommendations.append("- –°–æ–∑–¥–∞–π—Ç–µ –ø—Ä–æ—Å—Ç—ã–µ —Ñ–æ—Ä–º—ã –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏\n")
    recommendations.append("- –î–æ–±–∞–≤—å—Ç–µ –æ—Ç–∑—ã–≤—ã –∫–ª–∏–µ–Ω—Ç–æ–≤\n\n")
    
    recommendations.append("---\n")
    recommendations.append("*–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–∏—Å—Ç–µ–º–æ–π SEO –∞–Ω–∞–ª–∏–∑–∞*\n")
    
    return "".join(recommendations)


def main():
    parser = argparse.ArgumentParser(
        description='SEO –∞–Ω–∞–ª–∏–∑ —Å–∞–π—Ç–∞ –¥–ª—è GitHub Actions'
    )
    parser.add_argument(
        '--url',
        type=str,
        required=True,
        help='URL —Å–∞–π—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞'
    )
    
    args = parser.parse_args()
    
    print(f"\n{'='*60}")
    print(f"  SEO –ê–ù–ê–õ–ò–ó: {args.url}")
    print(f"{'='*60}\n")
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑
    results = analyze_url(args.url)
    
    if results:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON
        output_file = "analysis_result.json"
        print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ {output_file}...")
        
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(
                results,
                f,
                ensure_ascii=False,
                indent=2,
                default=lambda x: x.isoformat() if isinstance(x, datetime) else str(x)
            )
        
        print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º
        recommendations = generate_recommendations(results)
        rec_file = "recommendations_ru.md"
        
        print(f"\nüìù –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –≤ {rec_file}...")
        with open(rec_file, "w", encoding="utf-8") as f:
            f.write(recommendations)
        
        print(f"‚úÖ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {rec_file}")
        
        print(f"\n{'='*60}")
        print("‚ú® –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
        print(f"{'='*60}\n")
        
        return 0 if results.get('status') == 'success' else 1
    else:
        print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∞–Ω–∞–ª–∏–∑")
        return 1


if __name__ == "__main__":
    sys.exit(main())
