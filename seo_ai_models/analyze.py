#!/usr/bin/env python3
"""
–ü–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π SEO –∞–Ω–∞–ª–∏–∑ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π seo-ai-models.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ GitHub Actions –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ legalaipro.ru.
"""

import argparse
import json
import sys
import os
from datetime import datetime
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å –ø–æ–∏—Å–∫–∞ –º–æ–¥—É–ª–µ–π
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

try:
    from seo_ai_models.parsers.unified.unified_parser import UnifiedParser
    from seo_ai_models.models.seo_advisor.analyzers.enhanced_content_analyzer import EnhancedContentAnalyzer
    MODULES_AVAILABLE = True
except ImportError as e:
    print(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥—É–ª–∏ –∞–Ω–∞–ª–∏–∑–∞: {e}")
    print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –≤—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —á–µ—Ä–µ–∑: pip install -r requirements.txt")
    MODULES_AVAILABLE = False


def analyze_url_full(url):
    """
    –ü–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ URL —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º UnifiedParser –∏ EnhancedContentAnalyzer.    
    Args:
        url: URL –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        
    Returns:
        dict: –ü–æ–ª–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
    """
    print(f"\n{'='*60}")
    print(f"üîç SEO –ê–ù–ê–õ–ò–ó: {url}")
    print(f"{'='*60}\n")
    
    if not MODULES_AVAILABLE:
        print("‚ùå –ú–æ–¥—É–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã. –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∞–Ω–∞–ª–∏–∑.")
        return None
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞—Ä—Å–µ—Ä —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    print("‚öôÔ∏è  –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è UnifiedParser...")
    parser = UnifiedParser()

                    # –ü–∞—Ä—Å–∏–º URL
    print(f"füìÑ –ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {url}...")
    parsed_data = parser.parse_url(url)
