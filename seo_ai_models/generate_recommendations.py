#!/usr/bin/env python3
"""
–ì–µ–Ω–µ—Ä–∞—Ü–∏—è SEO-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞.
"""
import argparse
import json
import sys
from pathlib import Path
from seo_ai_models.models.seo_advisor.suggester.suggester import Suggester


def generate_recommendations(input_file: str, output_file: str) -> bool:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç SEO-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞.
    
    Args:
        input_file: –ü—É—Ç—å –∫ JSON —Ñ–∞–π–ª—É —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
        output_file: –ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É Markdown —Ñ–∞–π–ª—É
    
    Returns:
        bool: True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –≤ –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ
    """
    try:
        # –ß–∏—Ç–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
        print(f"üìÇ –ß—Ç–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑ {input_file}...")
        with open(input_file, 'r', encoding='utf-8') as f:
            analysis_data = json.load(f)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        print("‚öôÔ∏è –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Suggester...")
        suggester = Suggester()
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        print("‚ñ∂ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è SEO-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π...")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ analysis_data
        # –°–æ–∑–¥–∞–µ–º basic_recommendations –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
        basic_recommendations = {}
        
        # –°–æ–∑–¥–∞–µ–º feature_scores –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫ –∞–Ω–∞–ª–∏–∑–∞
        feature_scores = {}
        if 'content_analysis' in analysis_data:
            content = analysis_data['content_analysis']
            if 'readability' in content:
                feature_scores['readability'] = content['readability'].get('score', 0.5)
            if 'keyword_analysis' in content:
                feature_scores['keyword_density'] = content['keyword_analysis'].get('density', 0.5)
        
        if 'technical_seo' in analysis_data:
            tech = analysis_data['technical_seo']
            feature_scores['content_length'] = min(1.0, tech.get('content_length', 0) / 2000)
            
        if 'meta_tags' in analysis_data:
            meta = analysis_data['meta_tags']
            feature_scores['meta_tags'] = 1.0 if meta.get('title') and meta.get('description') else 0.5
            
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º industry (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 'general')
        industry = analysis_data.get('industry', 'general')
        
        # –í—ã–∑—ã–≤–∞–µ–º –º–µ—Ç–æ–¥ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        recommendations = suggester.generate_suggestions(
            basic_recommendations=basic_recommendations,
            feature_scores=feature_scores,
            industry=industry
        )        # –§–æ—Ä–º–∏—Ä—É–µ–º Markdown –æ—Ç—á–µ—Ç
        # –§–æ—Ä–º–∏—Ä—É–µ–º Markdown –æ—Ç—á–µ—Ç
        print(f"‚ñ† –°–æ–∑–¥–∞–Ω–∏–µ Markdown –æ—Ç—á–µ—Ç–∞...")
        
        markdown_lines = []
        markdown_lines.append("# –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ SEO-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏\n")
        markdown_lines.append(f"*–î–∞—Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:* {analysis_data.get('timestamp', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}\n")
        markdown_lines.append(f"*URL:* {analysis_data.get('url', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}\n\n")
        markdown_lines.append("---\n\n")
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        if recommendations:
            for category, suggestions_list in recommendations.items():
                # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                category_name = category.replace('_', ' ').title()
                markdown_lines.append(f"## {category_name}\n\n")
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                if suggestions_list:
                    for suggestion in suggestions_list:
                        markdown_lines.append(f"- {suggestion}\n")
                    markdown_lines.append("\n")
                else:
                    markdown_lines.append("*–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–µ—Ç*\n\n")
        else:
            markdown_lines.append("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã.\n")
        
        markdown_content = ''.join(markdown_lines)        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –≤ {output_file}...")
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        
        print(f"\n‚úÖ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã!\n")
        return True
        
    except FileNotFoundError:
        print(f"‚ùå –û—à–∏–±–∫–∞: –§–∞–π–ª {input_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return False
    except json.JSONDecodeError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
        return False
    except Exception as e:
        print(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∏–∑ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏."""
    parser = argparse.ArgumentParser(
        description='–ì–µ–Ω–µ—Ä–∞—Ü–∏—è SEO-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞'
    )
    parser.add_argument(
        '--input',
        required=True,
        help='–ü—É—Ç—å –∫ JSON —Ñ–∞–π–ª—É —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞'
    )
    parser.add_argument(
        '--output',
        required=True,
        help='–ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É Markdown —Ñ–∞–π–ª—É'
    )
    
    args = parser.parse_args()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
    success = generate_recommendations(args.input, args.output)
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–¥ –≤—ã—Ö–æ–¥–∞
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
