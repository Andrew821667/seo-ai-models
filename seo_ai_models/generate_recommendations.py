#!/usr/bin/env python3
"""
–ì–µ–Ω–µ—Ä–∞—Ü–∏—è SEO-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞.
"""
import argparse
import json
import sys
from pathlib import Path
from seo_ai_models.models.seo_advisor.suggester.suggester import Suggester


def generate_recommendations(input_file: str, output_file: str) -> bool:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç SEO-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞.
    
    Args:
        input_file: –ü—É—Ç—å –∫ JSON —Ñ–∞–π–ª—É —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
        output_file: –ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É Markdown —Ñ–∞–π–ª—É
    
    Returns:
        bool: True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –≤ –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ
    """
    try:
        # –ß–∏—Ç–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
        print(f"üìÇ –ß—Ç–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑ {input_file}...")
        with open(input_file, 'r', encoding='utf-8') as f:
            analysis_data = json.load(f)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        print("‚öôÔ∏è –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Suggester...")
        suggester = Suggester()
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        print("‚ñ∂ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è SEO-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π...")
        
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ analysis_data
        # –°–æ–∑–¥–∞–µ–º basic_recommendations –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
        basic_recommendations = {}
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –±–∞–∑–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫
        
        # –ê–Ω–∞–ª–∏–∑ content_length
        if 'technical_seo' in analysis_data:
            tech = analysis_data['technical_seo']
            content_len = tech.get('content_length', 0)
            
            if content_len < 300:
                basic_recommendations.setdefault('content_length', []).append(
                    "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –º–∞–ª—ã–π –æ–±—ä–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç–∞ ({} —Å–ª–æ–≤). –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 500-1000 —Å–ª–æ–≤.".format(content_len)
                )
            elif content_len < 1000:
                basic_recommendations.setdefault('content_length', []).append(
                    "–û–±—ä–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç–∞ ({} —Å–ª–æ–≤) –Ω–∏–∂–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–≥–æ. –î–æ–±–∞–≤—å—Ç–µ –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–µ–º—ã.".format(content_len)
                )
                
        # –ê–Ω–∞–ª–∏–∑ meta_tags
        if 'meta_tags' in analysis_data:
            meta = analysis_data['meta_tags']
            
            if not meta.get('title'):
                basic_recommendations.setdefault('meta_tags', []).append(
                    "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç meta title. –î–æ–±–∞–≤—å—Ç–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏."
                )
            elif len(meta.get('title', '')) < 30:
                basic_recommendations.setdefault('meta_tags', []).append(
                    "Meta title —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π. –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –¥–ª–∏–Ω–∞: 50-60 —Å–∏–º–≤–æ–ª–æ–≤."
                )
            elif len(meta.get('title', '')) > 70:
                basic_recommendations.setdefault('meta_tags', []).append(
                    "Meta title —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π. –°–æ–∫—Ä–∞—Ç–∏—Ç–µ –¥–æ 60 —Å–∏–º–≤–æ–ª–æ–≤."
                )
                
            if not meta.get('description'):
                basic_recommendations.setdefault('meta_tags', []).append(
                    "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç meta description. –î–æ–±–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–æ 160 —Å–∏–º–≤–æ–ª–æ–≤."
                )
                
        # –ê–Ω–∞–ª–∏–∑ readability
        if 'content_analysis' in analysis_data:
            content = analysis_data['content_analysis']
            if 'readability' in content:
                read_score = content['readability'].get('score', 0)
                if read_score < 0.4:
                    basic_recommendations.setdefault('readability', []).append(
                        "–ù–∏–∑–∫–∞—è —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞. –£–ø—Ä–æ—Å—Ç–∏—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏ –¥–æ–±–∞–≤—å—Ç–µ –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∏."
                    )
                    
        # –ï—Å–ª–∏ –Ω–µ—Ç –Ω–∏ –æ–¥–Ω–æ–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, –¥–æ–±–∞–≤–∏–º –æ–±—â—É—é
        if not basic_recommendations:
            basic_recommendations['general'] = ['–û—Å–Ω–æ–≤–Ω—ã–µ SEO-–º–µ—Ç—Ä–∏–∫–∏ –≤ –Ω–æ—Ä–º–µ. –ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ —Ä–∞–±–æ—Ç—É –Ω–∞–¥ –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º.']

        
        # –°–æ–∑–¥–∞–µ–º feature_scores –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫ –∞–Ω–∞–ª–∏–∑–∞
        feature_scores = {}
        if 'content_analysis' in analysis_data:
            content = analysis_data['content_analysis']
            if 'readability' in content:
                feature_scores['readability'] = content['readability'].get('score', 0.5)
            if 'keyword_analysis' in content:
                feature_scores['keyword_density'] = content['keyword_analysis'].get('density', 0.5)
        
        if 'technical_seo' in analysis_data:
            tech = analysis_data['technical_seo']
            feature_scores['content_length'] = min(1.0, tech.get('content_length', 0) / 2000)
            
        if 'meta_tags' in analysis_data:
            meta = analysis_data['meta_tags']
            feature_scores['meta_tags'] = 1.0 if meta.get('title') and meta.get('description') else 0.5
            
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º industry (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 'general')
        industry = analysis_data.get('industry', 'general')
        
        # –í—ã–∑—ã–≤–∞–µ–º –º–µ—Ç–æ–¥ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        recommendations = suggester.generate_suggestions(
            basic_recommendations=basic_recommendations,
            feature_scores=feature_scores,
            industry=industry
        )
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º Markdown –æ—Ç—á–µ—Ç
        print(f"‚ñ† –°–æ–∑–¥–∞–Ω–∏–µ Markdown –æ—Ç—á–µ—Ç–∞...")
        
        markdown_lines = []
        markdown_lines.append("# –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ SEO-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏\n")
        markdown_lines.append(f"*–î–∞—Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:* {analysis_data.get('timestamp', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}\n")
        markdown_lines.append(f"*URL:* {analysis_data.get('url', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}\n\n")
        markdown_lines.append("---\n\n")
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        if recommendations:
            for category, suggestions_list in recommendations.items():
                # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                category_name = category.replace('_', ' ').title()
                markdown_lines.append(f"## {category_name}\n\n")
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                if suggestions_list:
                    for suggestion in suggestions_list:
                        markdown_lines.append(f"- {suggestion}\n")
                    markdown_lines.append("\n")
                else:
                    markdown_lines.append("*–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–µ—Ç*\n\n")
        else:
            markdown_lines.append("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã.\n")
        
        markdown_content = ''.join(markdown_lines)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –≤ —Ñ–∞–π–ª
        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –≤ {output_file}...")
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        
        print("‚úÖ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã!")
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∏–∑ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏."""
    parser = argparse.ArgumentParser(
        description='–ì–µ–Ω–µ—Ä–∞—Ü–∏—è SEO-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞'
    )
    parser.add_argument(
        '--input',
        required=True,
        help='–ü—É—Ç—å –∫ JSON —Ñ–∞–π–ª—É —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞'
    )
    parser.add_argument(
        '--output',
        required=True,
        help='–ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É Markdown —Ñ–∞–π–ª—É'
    )
    
    args = parser.parse_args()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
    success = generate_recommendations(args.input, args.output)
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–¥ –≤—ã—Ö–æ–¥–∞
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
